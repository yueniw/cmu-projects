---
title: "Technical Appendix - Model"
author: "KaZAM"
date: "11/26/2021"
output: pdf_document
---

```{r,include=F}
library(dplyr)
library(ggplot2)
```

Part 1:loading bike activity dataset, station location dataset and weather dataset
```{r}
#loading bike activity
bike_data<-read.csv("/Users/ceciliaxia/Desktop/bike.csv")
#loading location data (containing longitude and latitude)
geo<-read.csv("/Users/ceciliaxia/Desktop/lon.csv")
#loading weather data
weather<-read.csv("/Users/ceciliaxia/Desktop/2771020.csv")
weather<-weather[20081:(20081+364),c(5,10,13)]
colnames(weather)[1]<-"day"
weather$day<-as.Date(weather$day)
```


Part 2: process bike activity dataset and join it with weather dataset
```{r}
dat<-bike_data
# convert the raw data the right format
dat$date<-as.POSIXct(dat$date, format="%Y-%m-%d %H:%M:%S")
dat$day<-as.Date(dat$date)
# add a column indicating which month the ride happened
dat$month<-months(dat$day)
# add a column indicating which day of the week the ride happened
dat$weekday<-weekdays(dat$day)
# add a column indicating whetehr the day the ride happened is weekday
dat$is_weekday<-ifelse(dat$weekday=="Sunday"|dat$weekday=="Saturday",0,1)
dat$station_id<-as.factor(dat$station_id)
# add a column indicating which hour of the day the ride happened
dat$hour<-format(dat$date,"%H")
# join the dat dataset with the location data
j_dat<-inner_join(dat,weather,by="day")
```

Part 3:calculate each stations' variance of availability 
```{r}
stations<-split(bike_data,bike_data$station_id)
name<-unique(bike_data$station_id)
#cal_var is a function to calculate variance of availability proportion
cal_var<-function(x){
  dat<-x
  return(variance=var(dat$availability))
}
#calculate variance of availability for each station
var<-data.frame(t(rbind(lapply(stations,cal_var))))
colnames(var)<-c("variance")
var$station_id<-as.numeric(rownames(var))
var$variance<-as.numeric(var$variance)
# join the variance dataset with location data
var_loc<-left_join(var,geo,by="station_id")
head(var_loc)
```


Part 4: bring in the 20 stations' ids selected by Technical Appendix - Clustering
```{r}
id<-c(31623, 31209, 31233, 31230, 31243, 31205, 31277, 31200, 31101, 31217, 31248, 31272, 31227, 31268, 31242, 31622,31219, 31221, 31288, 31655)
```



Part 5: add a column indicating whether availability is Yes or No using 20% as the threshold
```{r}
# select the data of the 20 stations
j1_dat<-j_dat[which(j_dat$station_id %in% id),]
# add a column indicating whether availability is Yes or No using 20% as the threshold
j1_dat$logi_av<-ifelse(j1_dat$availability_p>0.20,"Yes","No")
head(j1_dat)
```

Part 6:Check the proportion of Yes and No in column availability in the dataset
```{r}
count<-as.data.frame(table(j1_dat$logi_av))
count$p<-round(count$Freq/sum(count$Freq),2)
count$Freq<-count$Freq/1000
ggplot(count,aes(x=Var1,y=Freq,fill=p)) + geom_bar(stat="identity")+
geom_text(aes(label=p),vjust=-0.2) +
theme_minimal()+
theme(legend.position = "none")+
ylab("Count (in thousand)")+
xlab("Response variable (Availability)")+
ggtitle("Distribution of availability before stratified sampling")+
theme(plot.title = element_text(hjust = 0.5))
```


Part 7: do data sampling and make the proportion of Yes and No in column availability equal in the sampled dataset
```{r}
names(j1_dat)
input1<-j1_dat[,c(1,3,11,13,15:17)]
input1$logi_av<-as.factor(input1$logi_av)
set.seed(10)
# We sampled 100,000 records from both Yes and No
sub_idx<-sampling::strata(input1,stratanames = ("logi_av"),size=rep(100000,2),"srswor")
input<-input1[sub_idx$ID_unit,]
count<-as.data.frame(table(input$logi_av))
count$p<-round(count$Freq/sum(count$Freq),2)
count$Freq<-count$Freq/1000
ggplot(count,aes(x=Var1,y=Freq,fill=p)) + geom_bar(stat="identity")+
geom_text(aes(label=p),vjust=-0.2) +
theme_minimal()+
theme(legend.position = "none")+
ylab("Count (in thousand)")+
xlab("Response variable (Availability)")+
ggtitle("Distribution of availability after stratified sampling")+
theme(plot.title = element_text(hjust = 0.5))
```


Part 8: divide 24h by 30 minutes and assign each time a 30 minutes category (there are 48 categories in total)
```{r}
#assign each time a 30 minutes category
input$h_m<-format(input$date, format='%H:%M')
mins <- 30 * round(as.double(as.difftime(input$h_m, format = "%H:%M"), "mins") / 30)
input$h_m<-format(as.POSIXct(60 * mins, origin = "1970-01-01", tz = "GMT"), "%H:%M")
input$h_m<-as.factor(input$h_m)
# show hour_minute category
levels(input$h_m)
input$month<-as.factor(input$month)
# show month category
levels(input$month)
```

Part 9: make 20 categories for station_id  as the original levels doesn't work
```{r}
tmp1<-data.frame(station_id=unique(input$station_id),corres=rep(1:20))
input_f<-left_join(input,tmp1,by="station_id")[,-c(1:2)]
input_f$corres<-as.factor(input_f$corres)
# check whether the levels for the station_id is only 20 now
levels(input_f$corres)
head(input_f)
```

Part 10: Split the dataset into 95% training set and 5% test set
```{r}
set.seed(10)
#split the training set and test set
smp_size <- floor(0.95 * nrow(input_f))
train_ind <- sample(nrow(input_f), size = smp_size)
train <- input_f[train_ind, ]
test <- input_f[-train_ind, ]
```

Part 11: fit Random Forest Model to the training set and calculate the accuracy using test set
```{r}
rf1<-randomForest::randomForest(logi_av~.,data=train)
forest.pred <- predict(rf1,test)
# show the importance of each explanatory variable and decide whether to include all the variables
randomForest::importance(rf1)
# make a confusion matrix about the Actual and the Predicted
table(test$logi_av,forest.pred,dnn = c('Actual','Predicted'))
```


Part 12: fit logistics regression model on the training set and calculate the accuracy using test set
```{r}
logistic_model <- glm(logi_av~., 
                      data = train, 
                      family = "binomial")

predict_reg <- predict(logistic_model, 
                       test, type = "response")

predict_reg <- as.factor(ifelse(predict_reg>0.5, "Yes", "No"))
# make a confusion matrix about the Actual and the Predicted
table(test$logi, predict_reg,dnn = c('Actual','Predicted'))

```



